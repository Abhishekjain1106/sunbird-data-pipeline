from __future__ import division
import math
import psycopg2
import sys
import pandas as pd
from IPython.display import display
import json

 
def updateRequests(db, table, update_list):
    for r in update_list:
        cursor = db.cursor()
        batchNum = r['batch_number']
        requestId = r['request_id']
        insertQry = "UPDATE {0} SET batch_number = {1} WHERE request_id = '{2}'".format(table, batchNum, requestId)
        n = cursor.execute(insertQry)

def processRequests(totalRequestsDf, jobId, batchSize, db, table):
    # Compute parallelism from batchSize & totalRequests
    # update batch_number to table

    totalRequests = len(totalRequestsDf.index)
    print("totalRequests {0}".format(totalRequests))

    parallelism = int(math.ceil(totalRequests/batchSize))
    print("parallelism computed {0}".format(parallelism))

    totalRequestsDf["row_num"] = totalRequestsDf.groupby(by=['job_id'])['request_id'].transform(lambda x: x.rank())
    #display(totalRequestsDf)

    start_index = 1
    end_index = batchSize
    for i in range(1, parallelism+1):
        subSetDf = totalRequestsDf[(totalRequestsDf['row_num'] >= start_index) & (totalRequestsDf['row_num'] <= end_index)]
        subSetDf["batch_number"] = i
        print(start_index,end_index)
        updateRequests(db, table, json.loads(subSetDf.to_json(orient='records')))
        start_index = 1 + end_index
        end_index = end_index + batchSize
    db.commit()
    db.close()    
    return parallelism      

def postgresql_to_dataframe(db, select_query, column_names):
    cursor = db.cursor()
    try:
        cursor.execute(select_query)
    except (Exception, psycopg2.DatabaseError) as error:
        print("Error: %s" % error)
        return 1
    
    tupples = cursor.fetchall()
    
    df = pd.DataFrame(tupples, columns=column_names)
    #display(df)
    return df

def main(batchSize, jobId):
    host="{{postgres.db_url}}"
    port={{postgres.db_port}}
    user="{{postgres.db_username}}"
    password="{{postgres.db_password}}"
    database="{{postgres.db_name}}"
    url_connect = "jdbc:postgresql://{0}:{1}/{2}".format(host, port, database)
    table = "{{ env }}_job_request"

    db = psycopg2.connect(host=host, user=user, password=password, database=database, port=port)

    column_names = ["tag", "request_id", "job_id", "status", "request_data", "requested_by", "requested_channel", "dt_job_submitted", "download_urls", "dt_file_created", "dt_job_completed", "execution_time", "err_message", "iteration", "encryption_key", "batch_number"]
    
    selectQuery = "select * from {0} where job_id = '{1}' and status IN ('SUBMITTED', 'FAILED') and iteration < 3;".format(table, jobId)
    df = postgresql_to_dataframe(db, selectQuery, column_names)

    parallelism = processRequests(df, jobId, batchSize, db, table)
    return parallelism

batchSize =int(sys.argv[2])
jobId=sys.argv[1]
parallelism = main(batchSize, jobId) 
print("returning parallelism value: {0}".format(parallelism))