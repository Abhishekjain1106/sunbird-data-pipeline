telemetry-extractor-config: |
kafka {
  input.topic = "{{env}}.telemetry.ingest"
  output.success.topic = "{{env}}.flink.telemetry.raw"
  output.duplicate.topic = "{{env}}.flink.telemetry.duplicate"
  output.failed.topic = "{{env}}.flink.telemetry.failed"
  event.max.size = "1048576" # Max is only 1MB
  groupId = "{{env}}.telemetry.extractor.group"
  broker-servers = "{{kafka_brokers}}"
  zookeeper = "{{zookeepers}}"
}

task {
  parallelism = 1
  checkpointing.interval = 60000
  dedup {
    parallelism = {{telemetry_extractor_dedup_fn_parallelism}}
  }
  extraction {
    parallelism = {{telemetry_extractor_extractor_fn_parallelism}}
  }
}
redis {
  host = {{redis_host}}
  port = 6379
  connection {
    max = 2
    idle.min = 1
    idle.max = 2
    minEvictableIdleTimeSeconds = 120
    timeBetweenEvictionRunsSeconds = 300
  }
  database {
    duplicationstore.id = 1
    key.expiry.seconds = {{telemetry_extractor_redis_expiry_seconds}}
  }
}
