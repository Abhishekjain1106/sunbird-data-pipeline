# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

# Job
job.factory.class=org.apache.samza.job.yarn.YarnJobFactory
job.name=__env__.ObjectDeNormalization

# YARN
#yarn.package.path=file://${basedir}/target/${project.artifactId}-${pom.version}-distribution.tar.gz
yarn.package.path=http://__yarn_host__:__yarn_port__/__env__/${project.artifactId}-${pom.version}-distribution.tar.gz

# Task
task.class=org.ekstep.ep.samza.task.ObjectDeNormalizationTask
task.inputs=kafka.__env__.telemetry.item.de_normalized,kafka.__env__.telemetry.objects.de_normalized.retry
task.consumer.preferred=__env__.telemetry.item.de_normalized
task.checkpoint.factory=org.apache.samza.checkpoint.kafka.KafkaCheckpointManagerFactory
task.checkpoint.system=kafka
task.chooser.class=org.ekstep.ep.samza.chooser.TimerBasedChooserFactory

# Normally, this would be 3, but we have only one broker.
task.checkpoint.replication.factor=1
task.commit.ms=60000
task.window.ms=1800000

# Metrics
metrics.reporters=snapshot
metrics.reporter.snapshot.class=org.apache.samza.metrics.reporter.MetricsSnapshotReporterFactory
metrics.reporter.snapshot.stream=kafka.__env__.metrics

# Serializers
serializers.registry.json.class=org.apache.samza.serializers.JsonSerdeFactory
serializers.registry.metrics.class=org.apache.samza.serializers.MetricsSnapshotSerdeFactory
serializers.registry.string.class=org.apache.samza.serializers.StringSerdeFactory

# Systems
systems.kafka.samza.factory=org.apache.samza.system.kafka.KafkaSystemFactory
systems.kafka.samza.msg.serde=json
# systems.kafka.consumer.zookeeper.connect=localhost:2181/
systems.kafka.consumer.zookeeper.connect=__zookeepers__
systems.kafka.consumer.auto.offset.reset=smallest
systems.kafka.samza.offset.default=upcoming
#systems.kafka.producer.bootstrap.servers=localhost:9092
systems.kafka.producer.bootstrap.servers=__kafka_brokers__
systems.kafka.streams.metrics.samza.msg.serde=metrics

task.consumer.delayInMilliSeconds=__delayInMilliSeconds__
task.consumer.retryTimeInMilliSeconds=__retryTimeInMilliSeconds__

# Job Coordinator
job.coordinator.system=kafka
# Normally, this would be 3, but we have only one broker.
job.coordinator.replication.factor=1

output.success.topic.name=__env__.telemetry.objects.de_normalized
output.retry.topic.name=__env__.telemetry.objects.de_normalized.retry
output.failed.topic.name=__env__.telemetry.objects.de_normalized.fail

retry.backoff.base=__retryBackoffBaseInSeconds__
retry.backoff.limit=__retryLimit__
retry.backoff.limit.enable=__retryLimitEnable__

#denorm.config.file=/etc/samza-jobs/object-denormalization-additional-config.json
denorm.config.file=__objectDenormalizationAdditionalConfig__
object.service.endpoint=__objectServiceEndpoint__
fields.to.denormalize=id,type,subtype,parentid,parenttype,code,name
stores.retry.factory=org.apache.samza.storage.kv.RocksDbKeyValueStorageEngineFactory
stores.retry.key.serde=string
stores.retry.msg.serde=json
